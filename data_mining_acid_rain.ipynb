{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Acid Rain Based On Atmospheric Pollutant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "\n",
    "from sklearn import preprocessing \n",
    "\n",
    "#*************************knn*************************************\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "#*************************Naive Bayes *********************\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#*************************Naive Bayes stratified approach*********************\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract rain events\n",
    "The dataset consists of hourly data of amount of rainfall and pH level of the rainfall of 25 stations.\n",
    "\n",
    "However, not all stations have this data. In the stations that contain this information, not all data is valid.\n",
    "Hence those events are extracted where there is a valid rainfall event (defined by threshold of rainfall > 0.05mm) and there is a valid pH information of the particular rainfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rain_events(raw_station_data, RAIN_THRESHOLD=0.05 ):\n",
    "\tcount_rain_data_points = 0\n",
    "\n",
    "\train_events_only = raw_station_data.copy()\n",
    "\tfor each_station in rain_events_only:\n",
    "\n",
    "\t\t# remove NaN rows\n",
    "\t\tstation_cleaned = rain_events_only[each_station].dropna()\n",
    "        \n",
    "\t\t# remove events with no rainfall (NR)\n",
    "\t\tstation_cleaned = station_cleaned[station_cleaned.RAINFALL != 'NR']\n",
    "\t\tstation_cleaned = station_cleaned[station_cleaned.PH_RAIN != 'NR']\n",
    "\t\tstation_cleaned = station_cleaned[station_cleaned.PH_RAIN != 'nan']\n",
    "\n",
    "\t\t# filter events with little rain\n",
    "\t\tstation_cleaned = station_cleaned[station_cleaned.RAINFALL.astype(float) >= RAIN_THRESHOLD]\n",
    "\n",
    "       #Rain event of each station and the total rain event count over Taiwan is extracted.\n",
    "\t\train_events_only[each_station] = station_cleaned\n",
    "\t\tcount_rain_data_points = count_rain_data_points+len(station_cleaned)\n",
    "\n",
    "\treturn rain_events_only, count_rain_data_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acid rain\n",
    "\n",
    "If the pH level of a liquid is below 7, it is termed as acidic. The pH level of the rainwater is typically acidic (around 5.6) due to the natural gases like C02,gasses from volcano etc. However if the pH level drops below 5, it is harmful. \n",
    "\n",
    "After extracting the rain event which has valid pH values, we classify the event as acidic rain or non-acidic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_acid_rain(stations, PH_ACID_RAIN_THRESHOLD=5):\n",
    "\tcount_acid_rain_data_points = 0\n",
    "    \n",
    "   \n",
    "\tfor each_station in stations:\n",
    "       #Initialize all the events as non-acidic\n",
    "\t\tstations[each_station]['acid_rain'] = False\n",
    "\n",
    "\t\tfor index, row in stations[each_station].iterrows():\n",
    "\t\t\tif float(stations[each_station].loc[index,'PH_RAIN']) <= PH_ACID_RAIN_THRESHOLD:\n",
    "\t\t\t\tstations[each_station].loc[index,'acid_rain'] = True \n",
    "              # Get the count of total acid rain events.\n",
    "\t\t\t\tcount_acid_rain_data_points = count_acid_rain_data_points+1\n",
    "    \n",
    "\treturn stations, count_acid_rain_data_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window\n",
    "\n",
    "The raw data is split into 1 hour long events.In the Windowing process,  consecutive rain data points are accumulated into Rain\n",
    "Windows.  A Rain Window is considered as acidic when at least one of itâ€™s data points is labeled as acidic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_rain_windows(rain_events, window_mode=True):\n",
    "\n",
    "\train_windows = [] # list of rain windows, of all stations\n",
    "\tcount_windows=0\n",
    "\n",
    "\n",
    "\tfor each in rain_events:\n",
    "\t\t# take last data point -> new rain event\n",
    "\t\train_window = pd.DataFrame(columns=rain_events[each].columns)\n",
    "\t\t# iterrate background through rain events, until difference is > 1h\n",
    "\n",
    "\t\tif window_mode:\n",
    "\t\t\tfor index, row in rain_events[each].iterrows(): \n",
    "\t\t\t\trow.name = index # make sure index stays the same\n",
    "\t\t\t\train_window = rain_window.append(row)\n",
    "\n",
    "\t\t\t\t# HINT: the index is used to check if the next data point was also rain\n",
    "                #(this only works since the data points are sorted by time)\n",
    "\t\t\t\tif index+1 in rain_events[each].index:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\train_windows.append(rain_window)\n",
    "\t\t\t\t\train_window = pd.DataFrame(columns=rain_events[each].columns)\n",
    "\t\t\t\t\tcount_windows=count_windows+1\n",
    "\t\telse:\n",
    "\t\t\tfor index, row in rain_events[each].iterrows(): \n",
    "\t\t\t\trow.name = index # make sure index stays the same\n",
    "\t\t\t\train_window = rain_window.append(row)\n",
    "\t\t\t\train_windows.append(rain_window)\n",
    "\t\t\t\train_window = pd.DataFrame(columns=rain_events[each].columns)\n",
    "\t\t\t\tcount_windows=count_windows+1\n",
    "\t\t\t# if previous data points received, append window tripple (pre_values, window, acid)\n",
    "\n",
    "\n",
    "\treturn rain_windows, count_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract previous data points\n",
    "\n",
    "The rain water becomes acidic if the amount of pollutant in the atmosphere (Nox and SO2) is high. Hence we need to extract the pollutant level before the event of the rainfall. \n",
    "\n",
    "It is checked if there is a valid data for the NOx and SO2 one hour before every rain event.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_data_points(raw_data, rain_windows, number_of_previous_data_points=10):\n",
    "    \n",
    "\tanalytical_data = []\n",
    "\tcount_acidic_windows=0\n",
    "\tcount_no_valid_previous_data=0\n",
    "\tacid_rain_window = False\n",
    "    \n",
    "\t# rermark the dataset is pre cleaned, if data was NA it will be ignored\n",
    "\tfor each in rain_windows:\n",
    "\n",
    "\t\tindex=each.index.min()\n",
    "       # remark only one station can be in each window\n",
    "\t\tstation=each.station.min() \n",
    "        \n",
    "       #Extract the data of  previous hours of data.\n",
    "\t\tprevious_data_points = raw_data[station].loc[index-number_of_previous_data_points:index-1]\n",
    "\n",
    "\n",
    "       #Extract information if there was acid rain in the previous hours.\n",
    "\t\tif True in each[\"acid_rain\"].unique():\n",
    "\t\t\tacid_rain_window = True\n",
    "\t\t\tcount_acidic_windows=count_acidic_windows+1\n",
    "\t\telse:\n",
    "\t\t\tacid_rain_window = False\n",
    "\n",
    "\t\tif len(previous_data_points) > 0:\n",
    "           # only consider data when you have the NOx and SO2 1h before rain\n",
    "\t\t\tif previous_data_points.loc[index-1][\"NOx\"] != \"NR\" and previous_data_points.loc[index-1][\"SO2\"] != \"NR\":\n",
    "\t\t\t\tanalytical_data.append([previous_data_points, each, acid_rain_window])\n",
    "\t\telse: \n",
    "\t\t\tcount_no_valid_previous_data=count_no_valid_previous_data+1\n",
    "            \n",
    "\treturn analytical_data, count_acidic_windows, count_no_valid_previous_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional KPIs and handling time series data.\n",
    "\n",
    "Now we have extracted rain event, ensured that there is Nox and So2 data one hour prior to the event. \n",
    "\n",
    "In case of rainfall, the pollutants dissolve in the rainwater and causes acid rain. Hence the rainfall event effects the acidity of the rainfall event in the future. Hence rainfall is considered for the prediction.\n",
    "\n",
    "Observing the raw dataset, we see that rainwater is acidic during several months. These months have a higher temperature than the reset. Hence ambient temperature is considered for the prediction.\n",
    "\n",
    "In the previous function, we extract data over last several hours of the rain event. An average/Sum/Median of the pollutants in last several hours can provide a better estimate if the rainfall is acidic or not. \n",
    "\n",
    "\n",
    "To determine \n",
    "    a) If inclusion of rainfall improves the performance\n",
    "    \n",
    "    b) If inclusion of ambient temperature improves the performance\n",
    "    \n",
    "    c) If Average of last several hours of data of KPIs provide better performance\n",
    "    \n",
    "    d) If Sum of last several hours of data of KPIs provide better performance\n",
    "    \n",
    "    e) If Median of last several hours of data of KPIs provide better performance\n",
    "    \n",
    "    \n",
    "the function is written to provide all different combination of results. Later the performance can be compared to determine the best performing model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_matrix(analytical_data, function=\"avg\", include_rain=True, include_amb_temp=True, normalisation=True):\n",
    "\tcount_acidic_windows = 0\n",
    "\tcount_non_acidic_windows = 0\n",
    "\n",
    "\tanalytical_matrix_results = pd.DataFrame(columns=[\"ACID_RAIN\"]) \n",
    "    \n",
    "    \n",
    "   #To determine performance for the different combinations of KPI\n",
    "\tif include_rain and include_amb_temp:\n",
    "\t\tanalytical_matrix = pd.DataFrame(columns=[\"NOx\",\"SO2\",\"AMB_TEMP\",\"RAINFALL\"]) \n",
    "\telif include_rain and not include_amb_temp:\n",
    "\t\tanalytical_matrix = pd.DataFrame(columns=[\"NOx\",\"SO2\",\"RAINFALL\"]) \n",
    "\telif not include_rain and include_amb_temp:\n",
    "\t\tanalytical_matrix = pd.DataFrame(columns=[\"NOx\",\"SO2\",\"AMB_TEMP\"]) \n",
    "\telse:\n",
    "\t\tanalytical_matrix = pd.DataFrame(columns=[\"NOx\",\"SO2\"]) \n",
    "\n",
    "\n",
    "   #calculate averge & sum & median as requested by the function for the KPIs over several hours.\n",
    "\tfor each in analytical_data:\n",
    "\t\tSO2=0\n",
    "\t\tNOx=0\n",
    "\t\tAMB_TEMP=0\n",
    "\t\tRAINFALL=0\n",
    "\n",
    "\t\teach[0] = each[0].replace(\"NR\", np.nan, regex=True)\n",
    "\n",
    "\t\tif function==\"avg\":\n",
    "\t\t\tSO2 = each[0][\"SO2\"].astype(float).mean()\n",
    "\t\t\tNOx = each[0][\"NOx\"].astype(float).mean()\n",
    "\t\t\tif include_rain:\n",
    "\t\t\t\tRAINFALL = each[0][\"RAINFALL\"].astype(float).mean()\n",
    "\t\t\tif include_amb_temp:\n",
    "\t\t\t\tAMB_TEMP = each[0][\"AMB_TEMP\"].astype(float).mean()\n",
    "\t\telif function==\"sum\":\n",
    "\t\t\tSO2 = each[0][\"SO2\"].astype(float).sum()\n",
    "\t\t\tNOx = each[0][\"NOx\"].astype(float).sum()\n",
    "\t\t\tAMB_TEMP = each[0][\"AMB_TEMP\"].astype(float).sum()\n",
    "\t\t\tif include_rain:\n",
    "\t\t\t\tRAINFALL = each[0][\"RAINFALL\"].astype(float).sum()\n",
    "\t\t\tif include_amb_temp:\n",
    "\t\t\t\tAMB_TEMP = each[0][\"AMB_TEMP\"].astype(float).sum()\n",
    "\t\telif function==\"median\":\n",
    "\t\t\tSO2 = each[0][\"SO2\"].astype(float).median()\n",
    "\t\t\tNOx = each[0][\"NOx\"].astype(float).median()\n",
    "\t\t\tAMB_TEMP = each[0][\"AMB_TEMP\"].astype(float).median()\n",
    "\t\t\tif include_rain:\n",
    "\t\t\t\tRAINFALL = each[0][\"RAINFALL\"].astype(float).median()\n",
    "\t\t\tif include_amb_temp:\n",
    "\t\t\t\tAMB_TEMP = each[0][\"AMB_TEMP\"].astype(float).median()\n",
    "\t\t\n",
    "\t\t# REMARK: for statistical purposes \n",
    "\t\tif each[2] == True:\n",
    "\t\t\tcount_acidic_windows=count_acidic_windows+1\n",
    "\t\telse:\n",
    "\t\t\tcount_non_acidic_windows=count_non_acidic_windows+1\n",
    "\n",
    "\n",
    "       #Output a matrix which contains the sum/average/median of NOx,SO2 and if requested Rainfall,Ambient temperature.\n",
    "\t\tif include_rain and include_amb_temp:\n",
    "\t\t\tappending_dict = {\"NOx\": NOx, \"SO2\": SO2, \"RAINFALL\": RAINFALL, \"AMB_TEMP\": AMB_TEMP }\n",
    "\t\telif include_rain and not include_amb_temp:\n",
    "\t\t\tappending_dict = {\"NOx\": NOx, \"SO2\": SO2, \"RAINFALL\": RAINFALL }\n",
    "\t\telif not include_rain and include_amb_temp:\n",
    "\t\t\tappending_dict = {\"NOx\": NOx, \"SO2\": SO2, \"AMB_TEMP\": AMB_TEMP }\n",
    "\t\telse:\n",
    "\t\t\tappending_dict = {\"NOx\": NOx, \"SO2\": SO2}\n",
    "\n",
    "\n",
    "\t\tanalytical_matrix = analytical_matrix.append(appending_dict, ignore_index=True)\n",
    "       \n",
    "       #Provide the information about if the rainfall event was acidic or not\n",
    "\t\tanalytical_matrix_results = analytical_matrix_results.append({\"ACID_RAIN\": int(each[2])}, ignore_index=True)\n",
    "\n",
    "\treturn analytical_matrix, analytical_matrix_results, count_acidic_windows,count_non_acidic_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring performance.\n",
    "\n",
    "The performance of the algorithm is measured via F1 score. However Precision score,Recall score and accuracy is also recorded.\n",
    "\n",
    "Following classifiers are used :\n",
    "\n",
    "1) knn classifier\n",
    "\n",
    "2) Naive Bayes classifier\n",
    "\n",
    "3) Naive Bayes classifier with 5 fold stratified approach\n",
    "\n",
    "4) Naive Bayes classifier with 10 fold stratified approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_results(analytical_dataframe, analytical_dataframe_results):\n",
    "    \n",
    "\ttest_results = pd.DataFrame(columns=[\"classifier\", \n",
    "                                      \"knn_parameters\", \n",
    "                                      \"test_size\", \"f1_score\", \n",
    "                                      \"precsission\", \"recall\", \"accuracy\", \n",
    "                                      \"confusion_matrix\"])\n",
    "    \n",
    "\tdataset_all_stations=analytical_dataframe.fillna(0.0)\n",
    "\tpH_level_all_stations = []\n",
    "       \n",
    "\tfor each in analytical_dataframe_results.fillna(0.0).values:\n",
    "\t\tpH_level_all_stations.append(each[0])\n",
    "        \n",
    "   #split the data to training and test set (Ratio 80% and 20%)\n",
    "\tdata_train, data_test, target_train, target_test = train_test_split(dataset_all_stations,pH_level_all_stations,test_size=0.2, random_state=1)\n",
    "\n",
    "   #Normalizing the data set\n",
    "\tx = data_train.fillna(0.0).values #returns a numpy array\n",
    "\tmin_max_scaler = preprocessing.MinMaxScaler()\n",
    "\tmin_max_scaler.fit(x)\n",
    "\tx_scaled = min_max_scaler.transform(x)\n",
    "\tdata_train = pd.DataFrame(x_scaled) # normalised data set\n",
    "\n",
    "\tx = data_test.fillna(0.0).values #returns a numpy array\n",
    "   #scale the test set using the same normalizing factor as training set.\n",
    "\tx_scaled = min_max_scaler.transform(x)\n",
    "\tdata_test = pd.DataFrame(x_scaled) # normalised data set\n",
    "    \n",
    "\tdataset_all_stations_normalized = preprocessing.MinMaxScaler().fit_transform(dataset_all_stations)\n",
    "\n",
    "   #***********************knn classifier*************************************\n",
    "\tknn_estimator = KNeighborsClassifier()\n",
    "   #Set the parameters\n",
    "\tparameters = {\n",
    "\t \t'n_neighbors': range(2, 9), \n",
    "\t \t'algorithm': ['ball_tree', 'kd_tree', 'brute']}\n",
    "\tstratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\tgrid_search_estimator = GridSearchCV(knn_estimator, parameters, scoring='f1_macro', cv=stratified_10_fold_cv)\n",
    "\n",
    "   #Determine the best algorithm and optimal neighbour which gives the best performance.\n",
    "\tgrid_search_estimator.fit(data_train,target_train) \n",
    "   #Perform the prediction on the test set with the same parameter.\n",
    "\tpredict = grid_search_estimator.predict(data_test)\n",
    "\n",
    "   #Output results\n",
    "\ttest_results = test_results.append({\"classifier\": \"knn\", \"knn_parameters\": format(grid_search_estimator.best_params_), \n",
    "                                     \"test_size\": 0.2, \n",
    "                                     \"f1_score\": f1_score(target_test,predict, average=\"macro\"), \n",
    "                                     \"precsission\": precision_score(target_test, predict, average=\"macro\"),\n",
    "                                     \"recall\": recall_score(target_test, predict, average=\"macro\"), \n",
    "                                     \"accuracy\": accuracy_score(target_test, predict), \n",
    "                                     \"confusion_matrix\": confusion_matrix(target_test, predict)}, ignore_index=True)\n",
    "    \n",
    "    \n",
    "   #**************************Naive Bayes*************************************\n",
    "\tnaive_bayes = GaussianNB()\n",
    "\tnaive_bayes.fit(data_train,target_train) \n",
    "\tpredict = naive_bayes.predict(data_test)\n",
    "    \n",
    "   #Output results\n",
    "\ttest_results = test_results.append({\"classifier\": \"nb\", \"knn_parameters\": \"\", \"test_size\": 0.2,\n",
    "                                     \"f1_score\": f1_score(target_test,predict, average=\"macro\"),\n",
    "                                     \"precsission\": precision_score(target_test, predict, average=\"macro\"),\n",
    "                                     \"recall\": recall_score(target_test, predict, average=\"macro\"),\n",
    "                                     \"accuracy\": accuracy_score(target_test, predict),\n",
    "                                     \"confusion_matrix\": confusion_matrix(target_test, predict)}, ignore_index=True)\n",
    "\n",
    "   #***********************Naive Bayes 5 fold stratified*********************\n",
    "\tcv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\tpredict = cross_val_predict(naive_bayes, dataset_all_stations_normalized, pH_level_all_stations, cv=cv)\n",
    "\n",
    "   #Output results\n",
    "\ttest_results = test_results.append({\"classifier\": \"nb5\", \"knn_parameters\": \"\", \n",
    "                                     \"test_size\": \"5 fold\",\n",
    "                                     \"f1_score\": f1_score(pH_level_all_stations,predict, average=\"macro\"),\n",
    "                                     \"precsission\": precision_score(pH_level_all_stations, predict, average=\"macro\"), \n",
    "                                     \"recall\": recall_score(pH_level_all_stations, predict, average=\"macro\"),\n",
    "                                     \"accuracy\": accuracy_score(pH_level_all_stations, predict), \n",
    "                                     \"confusion_matrix\": confusion_matrix(pH_level_all_stations, predict)}, ignore_index=True)\n",
    "    \n",
    "    \n",
    "   #***********************Naive Bayes 10 fold stratified*********************\n",
    "\tcv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\tpredict = cross_val_predict(naive_bayes, dataset_all_stations_normalized, pH_level_all_stations, cv=cv)\n",
    "\n",
    "   #Output results\n",
    "\ttest_results = test_results.append({\"classifier\": \"nb10\", \"knn_parameters\": \"\", \n",
    "                                     \"test_size\": \"10 fold\", \n",
    "                                     \"f1_score\": f1_score(pH_level_all_stations,predict, average=\"macro\"), \n",
    "                                     \"precsission\": precision_score(pH_level_all_stations, predict, average=\"macro\"),\n",
    "                                     \"recall\": recall_score(pH_level_all_stations, predict, average=\"macro\"), \n",
    "                                     \"accuracy\": accuracy_score(pH_level_all_stations, predict),\n",
    "                                     \"confusion_matrix\": confusion_matrix(pH_level_all_stations, predict)}, ignore_index=True)\n",
    "    \n",
    "   #Return the results of all the classifiers. \n",
    "\treturn test_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze results\n",
    "\n",
    "Given previous data of the rain events, this function combines the previous data using sum/average/median of KPIs (setup_matrix)and provides the result of the classifier (measure_results).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyse_results(analytical_windows, function=\"avg\", include_rain=True, include_amb_temp=True):\n",
    "\tprint(\"...calculating results = include rain:\", include_rain, \",include ambient temperature:\", include_amb_temp, \"and aggregation function:\", function)\n",
    "\tanalytical_dataframe, analytical_dataframe_results ,count_acidic_windows, count_non_acidic_windows = setup_matrix(analytical_windows, function=function, include_rain=include_rain, include_amb_temp=include_amb_temp)\n",
    "\treturn measure_results(analytical_dataframe, analytical_dataframe_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./2015_Air_quality_in_northern_Taiwan.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Throwing out invalid data\n",
    "\n",
    "The data set contains several invalid data\n",
    "\n",
    "\\# indicates invalid value by equipment inspection\n",
    "\n",
    "\\* indicates invalid value by program inspection\n",
    "\n",
    "x indicates invalid value by human inspection\n",
    "\n",
    "NR indicates no rainfall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.mask(dataset.applymap(lambda x: '#' in x if  isinstance(x,str) else False))  \n",
    "dataset = dataset.mask(dataset.applymap(lambda x: '*' in x if  isinstance(x,str) else False)) \n",
    "dataset = dataset.mask(dataset.applymap(lambda x: 'x' in x if  isinstance(x,str) else False))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the algorithm for various combination\n",
    "\n",
    "The below code is configured for the best parameter settings. In case different combination results are required,refer to the comment section in the code to obtain different configuration results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND 3337 rain data points, with less than 0.01 L/hour rain, in all stations combined.\n",
      "FOUND 1740 acid rain data points, with PH_RAIN value below 4.5 , in all stations combined.\n",
      "...calculating results = include rain: True ,include ambient temperature: True and aggregation function: avg\n",
      "run 0   previous_datapoints   nox   sox  rain ambient_temperature function windowed  \\\n",
      "0                 600  True  True  True                True      avg    False   \n",
      "1                 600  True  True  True                True      avg    False   \n",
      "2                 600  True  True  True                True      avg    False   \n",
      "3                 600  True  True  True                True      avg    False   \n",
      "\n",
      "  classifier                                knn_parameters  ph_value  \\\n",
      "0        knn  {'algorithm': 'ball_tree', 'n_neighbors': 3}       4.5   \n",
      "1         nb                                                     4.5   \n",
      "2        nb5                                                     4.5   \n",
      "3       nb10                                                     4.5   \n",
      "\n",
      "   test_size acid_rain_events non_acid_rain_events  rain_TH  f1_score  \\\n",
      "0        0.2             1597                 1740     0.01  0.825520   \n",
      "1        0.2             1597                 1740     0.01  0.585623   \n",
      "2        0.2             1597                 1740     0.01  0.601680   \n",
      "3        0.2             1597                 1740     0.01  0.603717   \n",
      "\n",
      "   precsission    recall  accuracy           confusion_matrix  \n",
      "0     0.828891  0.825091  0.826347     [[253, 72], [44, 299]]  \n",
      "1     0.594939  0.589693  0.592814   [[154, 171], [101, 242]]  \n",
      "2     0.611700  0.604999  0.610129  [[775, 822], [479, 1261]]  \n",
      "3     0.614003  0.607062  0.612227  [[777, 820], [474, 1266]]  \n"
     ]
    }
   ],
   "source": [
    "raw_data = dict(tuple(dataset[['time','station','NOx', 'SO2', 'PH_RAIN', 'RAINFALL', 'AMB_TEMP']].sort_values('time').groupby('station')))\n",
    "\n",
    "RAIN_THRESHOLD = 0.01\n",
    "ph_value=[4.5]\n",
    "windows=[False]\n",
    "data_points=[600]\n",
    "include_rain=[True]\n",
    "include_amb_temp=[True]\n",
    "function=[\"avg\"]\n",
    "\"\"\"\n",
    "Different possible combination of parameter setting\n",
    "\n",
    "ph_value=[4.5,5.0]\n",
    "windows=[False]\n",
    "data_points=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,25,30,50,100,150,300,600]\n",
    "include_rain=[False,True]\n",
    "include_amb_temp=[False,True]\n",
    "function=[\"avg\", \"sum\", \"median\"]\n",
    "\"\"\"\n",
    "\n",
    "combined_results = pd.DataFrame(columns=[\"previous_datapoints\", \"nox\", \"sox\", \"rain\", \"ambient_temperature\", \"function\", \"windowed\", \"classifier\", \"knn_parameters\", \"ph_value\", \"test_size\", \"acid_rain_events\", \"non_acid_rain_events\", \"rain_TH\", \"f1_score\", \"precsission\", \"recall\", \"accuracy\", \"confusion_matrix\"])\n",
    "\n",
    "i=0\n",
    "for each_ph_value in ph_value:\n",
    "\train_events, count_rain_events = filter_rain_events(raw_data, RAIN_THRESHOLD)\n",
    "\tprint(\"FOUND\", count_rain_events, \"rain data points, with less than\", RAIN_THRESHOLD, \"L/hour rain, in all stations combined.\")\n",
    "\tmarked_rain_events, count_acid_rain_events = mark_acid_rain(rain_events, each_ph_value)\n",
    "\tprint(\"FOUND\", count_acid_rain_events, \"acid rain data points, with PH_RAIN value below\", each_ph_value, \", in all stations combined.\")\n",
    "\tfor each_window in windows:\n",
    "\t\tfor each_data_point in data_points:\n",
    "\t\t\tfor each_rain in include_rain:\n",
    "\t\t\t\tfor each_amb_temp in include_amb_temp:\n",
    "\t\t\t\t\tif each_data_point > 1:\n",
    "\t\t\t\t\t\tfor each_function in function:\n",
    "\t\t\t\t\t\t\train_windows, count_rain_windows, = build_rain_windows(marked_rain_events, window_mode=each_window)\n",
    "\n",
    "\t\t\t\t\t\t\tanalytical_windows, count_acid_rain_windows, count_no_valid_previous_data = get_previous_data_points(raw_data, rain_windows, each_data_point) \n",
    "\t\t\t\t\t\t\ttest_results = analyse_results(analytical_windows, function=each_function, include_rain=each_rain, include_amb_temp=each_amb_temp)\n",
    "\n",
    "\t\t\t\t\t\t\tcurrent_configuration = {\"previous_datapoints\": each_data_point, \"nox\" : True, \"sox\": True, \"rain\": each_rain, \"ambient_temperature\": each_amb_temp, \"function\": each_function, \"windowed\": each_window, \"ph_value\": each_ph_value, \"test_size\": 0.2, \"acid_rain_events\": count_rain_windows-count_acid_rain_windows, \"non_acid_rain_events\": count_acid_rain_windows, \"rain_TH\": RAIN_THRESHOLD} \n",
    "\n",
    "\t\t\t\t\t\t\tfor each in test_results.to_dict(orient='records'):\n",
    "\t\t\t\t\t\t\t\teach.update(current_configuration)\n",
    "\t\t\t\t\t\t\t\tcombined_results = combined_results.append(each, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\train_windows, count_rain_windows, = build_rain_windows(marked_rain_events, window_mode=each_window)\n",
    "\t\t\n",
    "\t\t\t\t\t\tanalytical_windows, count_acid_rain_windows, count_no_valid_previous_data = get_previous_data_points(raw_data, rain_windows, each_data_point)\n",
    "\t\t\t\t\t\ttest_results = analyse_results(analytical_windows, function=\"avg\", include_rain=each_rain, include_amb_temp=each_amb_temp)\n",
    "\n",
    "\t\t\t\t\t\tcurrent_configuration = {\"previous_datapoints\": each_data_point, \"nox\" : True, \"sox\": True, \"rain\": each_rain, \"ambient_temperature\": each_amb_temp, \"function\": \"\", \"windowed\": each_window, \"ph_value\": each_ph_value, \"test_size\": 0.2, \"acid_rain_events\": count_rain_windows-count_acid_rain_windows, \"non_acid_rain_events\": count_acid_rain_windows, \"rain_TH\": RAIN_THRESHOLD} \n",
    "\n",
    "\t\t\t\t\t\tfor each in test_results.to_dict(orient='records'):\n",
    "\t\t\t\t\t\t\teach.update(current_configuration)\n",
    "\t\t\t\t\t\t\tcombined_results = combined_results.append(each, ignore_index=True)\n",
    "\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\tif i%50 == 0:\n",
    "\t\t\t\t\t\t\tprint(\"run\", i, combined_results)\n",
    "\t\t\t\t\telse: \n",
    "\t\t\t\t\t\tprint(\"run\", i, \"next intermediate print in\" ,-(i % 50 - 50), \"runs\")\n",
    "\n",
    "\t\t\t\t\ti=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>previous_datapoints</th>\n",
       "      <th>nox</th>\n",
       "      <th>sox</th>\n",
       "      <th>rain</th>\n",
       "      <th>ambient_temperature</th>\n",
       "      <th>function</th>\n",
       "      <th>windowed</th>\n",
       "      <th>classifier</th>\n",
       "      <th>knn_parameters</th>\n",
       "      <th>ph_value</th>\n",
       "      <th>test_size</th>\n",
       "      <th>acid_rain_events</th>\n",
       "      <th>non_acid_rain_events</th>\n",
       "      <th>rain_TH</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precsission</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>avg</td>\n",
       "      <td>False</td>\n",
       "      <td>knn</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 3}</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1597</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.825520</td>\n",
       "      <td>0.828891</td>\n",
       "      <td>0.825091</td>\n",
       "      <td>0.826347</td>\n",
       "      <td>[[253, 72], [44, 299]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>avg</td>\n",
       "      <td>False</td>\n",
       "      <td>nb</td>\n",
       "      <td></td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1597</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.585623</td>\n",
       "      <td>0.594939</td>\n",
       "      <td>0.589693</td>\n",
       "      <td>0.592814</td>\n",
       "      <td>[[154, 171], [101, 242]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>avg</td>\n",
       "      <td>False</td>\n",
       "      <td>nb5</td>\n",
       "      <td></td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1597</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.601680</td>\n",
       "      <td>0.611700</td>\n",
       "      <td>0.604999</td>\n",
       "      <td>0.610129</td>\n",
       "      <td>[[775, 822], [479, 1261]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>avg</td>\n",
       "      <td>False</td>\n",
       "      <td>nb10</td>\n",
       "      <td></td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1597</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.603717</td>\n",
       "      <td>0.614003</td>\n",
       "      <td>0.607062</td>\n",
       "      <td>0.612227</td>\n",
       "      <td>[[777, 820], [474, 1266]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  previous_datapoints   nox   sox  rain ambient_temperature function windowed  \\\n",
       "0                 600  True  True  True                True      avg    False   \n",
       "1                 600  True  True  True                True      avg    False   \n",
       "2                 600  True  True  True                True      avg    False   \n",
       "3                 600  True  True  True                True      avg    False   \n",
       "\n",
       "  classifier                                knn_parameters  ph_value  \\\n",
       "0        knn  {'algorithm': 'ball_tree', 'n_neighbors': 3}       4.5   \n",
       "1         nb                                                     4.5   \n",
       "2        nb5                                                     4.5   \n",
       "3       nb10                                                     4.5   \n",
       "\n",
       "   test_size acid_rain_events non_acid_rain_events  rain_TH  f1_score  \\\n",
       "0        0.2             1597                 1740     0.01  0.825520   \n",
       "1        0.2             1597                 1740     0.01  0.585623   \n",
       "2        0.2             1597                 1740     0.01  0.601680   \n",
       "3        0.2             1597                 1740     0.01  0.603717   \n",
       "\n",
       "   precsission    recall  accuracy           confusion_matrix  \n",
       "0     0.828891  0.825091  0.826347     [[253, 72], [44, 299]]  \n",
       "1     0.594939  0.589693  0.592814   [[154, 171], [101, 242]]  \n",
       "2     0.611700  0.604999  0.610129  [[775, 822], [479, 1261]]  \n",
       "3     0.614003  0.607062  0.612227  [[777, 820], [474, 1266]]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
